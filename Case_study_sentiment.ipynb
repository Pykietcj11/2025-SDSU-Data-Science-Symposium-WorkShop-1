{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ff6908f",
   "metadata": {},
   "source": [
    "# Using Streamlit with Ollama for sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5b814c",
   "metadata": {},
   "source": [
    "    In this section we will go over how we can pair ollama with streamlit to use NLP with ollama to perform sentiment analysis on text. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a34221b",
   "metadata": {},
   "source": [
    "## 1. Install necessary Packages\n",
    "    !pip install ollama streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce5aef52",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in /opt/anaconda3/lib/python3.11/site-packages (0.3.3)\n",
      "Requirement already satisfied: streamlit in /opt/anaconda3/lib/python3.11/site-packages (1.39.0)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /opt/anaconda3/lib/python3.11/site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (4.2.2)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (14.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (8.2.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (4.11.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: entrypoints in /opt/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
      "Requirement already satisfied: toolz in /opt/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.2.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.11/site-packages (from pandas<3,>=1.4.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (2.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich<14,>=10.14.0->streamlit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce4cf931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test ollama to make sure it works\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "957eb5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [{'name': 'spam_Ollama:latest',\n",
       "   'model': 'spam_Ollama:latest',\n",
       "   'modified_at': '2024-12-05T16:18:29.756616099-06:00',\n",
       "   'size': 807691078,\n",
       "   'digest': 'a5aa4550ffc57110ae2c2c2ae3f1108eb8bfdc938d552f93de7bd8ad0ba10d07',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '1.2B',\n",
       "    'quantization_level': 'Q4_K_M'}},\n",
       "  {'name': 'llama3.2:latest',\n",
       "   'model': 'llama3.2:latest',\n",
       "   'modified_at': '2024-10-16T19:26:18.135739959-05:00',\n",
       "   'size': 2019393189,\n",
       "   'digest': 'a80c4f17acd55265feec403c7aef86be0c25983ab279d83f3bcd3abbcb5b8b72',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '3.2B',\n",
       "    'quantization_level': 'Q4_K_M'}}]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38a01f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2', 'created_at': '2025-01-30T17:51:22.690776Z', 'message': {'role': 'assistant', 'content': \"A large language model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language. It's trained on vast amounts of text data, which enables it to learn patterns, relationships, and context. LLMs use complex algorithms to generate responses, answers, or text based on the input they receive. They can be used for tasks such as language translation, text summarization, question answering, and more. LLMs have become increasingly popular in areas like natural language processing (NLP), chatbots, and virtual assistants due to their ability to understand and respond to human-like language inputs.\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 9845562292, 'load_duration': 816609125, 'prompt_eval_count': 37, 'prompt_eval_duration': 4087000000, 'eval_count': 127, 'eval_duration': 4937000000}\n"
     ]
    }
   ],
   "source": [
    "## To chat with llma3.2\n",
    "prompt={'role':'user', 'content':\"With approximately 100 words explain what is large language model?\"}\n",
    "llm='llama3.2'\n",
    "response = ollama.chat(model=llm, messages=[prompt])\n",
    "\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a125eb4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model (LLM) is a type of artificial intelligence (AI) designed to process and understand human language. It's trained on vast amounts of text data, which enables it to learn patterns, relationships, and context. LLMs use complex algorithms to generate responses, answers, or text based on the input they receive. They can be used for tasks such as language translation, text summarization, question answering, and more. LLMs have become increasingly popular in areas like natural language processing (NLP), chatbots, and virtual assistants due to their ability to understand and respond to human-like language inputs.\n"
     ]
    }
   ],
   "source": [
    "answer = response['message']['content']\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff51b3a6",
   "metadata": {},
   "source": [
    "## 2. Create a simple application with streamlit as a foundation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29d146fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sentiment_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sentiment_app.py\n",
    "\n",
    "import streamlit as st\n",
    "import ollama\n",
    "\n",
    "st.title('Ollama Sentiment Analysis')\n",
    "st.caption('''\n",
    "    This application is used to perform sentiment analysis \n",
    "    on input text data and will score the input as \"Positive\",\n",
    "    \"Negative\", or \"Neutral.\"\n",
    "    ''')\n",
    "\n",
    "llm='llama3.2'\n",
    "user_input = str(st.chat_input('Place text for review here:'))\n",
    "\n",
    "response=ollama.generate(model=llm, prompt=\"Respond only with 'Positive' or 'Negative' or 'Neutral' for the review:\"+user_input)\n",
    "\n",
    "if user_input:\n",
    "    contents=response['response']\n",
    "    st.write(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7c99b71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8503\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.112.132.163:8503\u001b[0m\n",
      "\u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!streamlit run sentiment_app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "975749fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sentiment_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sentiment_app.py\n",
    "\n",
    "import streamlit as st\n",
    "import ollama\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Sidebar for selecting application mode\n",
    "page = st.sidebar.selectbox(\n",
    "    \"Choose a Mode\",\n",
    "    [\"Ollama Chat\", \"Sentiment Analysis\"]\n",
    ")\n",
    "\n",
    "if page == \"Ollama Chat\":\n",
    "    st.title(\"Ollama Chat\")\n",
    "    st.caption(\"A simple chatbot using Ollama.\")\n",
    "\n",
    "    if \"chat_history\" not in st.session_state:\n",
    "        st.session_state.chat_history = []\n",
    "\n",
    "    user_input = st.text_input(\"Enter your message:\")\n",
    "    \n",
    "    if user_input:\n",
    "        response = ollama.generate(model=\"llama3.2\", prompt=user_input)\n",
    "        if 'response' in response:\n",
    "            st.session_state.chat_history.append((\"You\", user_input))\n",
    "            st.session_state.chat_history.append((\"Ollama\", response['response']))\n",
    "    \n",
    "    for sender, msg in st.session_state.chat_history:\n",
    "        st.write(f\"**{sender}:** {msg}\")\n",
    "\n",
    "\n",
    "elif page == \"Sentiment Analysis\":\n",
    "    st.title(\"Ollama Sentiment Analysis\")\n",
    "    st.caption(\n",
    "        \"Enter text to classify sentiment as 'Positive', 'Negative', or 'Neutral'.\\n\\n\"\n",
    "        \"This works by using a prompt-based approach with Ollama, where the model is \"\n",
    "        \"instructed to strictly respond with one of the three sentiment labels. \"\n",
    "        \"By carefully crafting the prompt, we guide the model to provide structured \"\n",
    "        \"and predictable responses, ensuring consistency in sentiment classification.\"\n",
    "    )\n",
    "\n",
    "    analysis_mode = st.radio(\"Choose Input Mode:\", [\"Single Review\", \"Batch Processing (CSV)\"])\n",
    "\n",
    "    if analysis_mode == \"Single Review\":\n",
    "        user_input = st.chat_input(\"Place text for review here:\")\n",
    "\n",
    "        if user_input:\n",
    "            sentiment_prompt = f\"Classify the following review as 'Positive', 'Negative', or 'Neutral': {user_input}\"\n",
    "            response = ollama.generate(model=\"llama3.2\", prompt=sentiment_prompt)\n",
    "\n",
    "            if 'response' in response:\n",
    "                st.write(f\"**Sentiment:** {response['response']}\")\n",
    "\n",
    "    elif analysis_mode == \"Batch Processing (CSV)\":\n",
    "        uploaded_file = st.file_uploader(\"Upload a CSV file with a column named 'review'\", type=[\"csv\"])\n",
    "\n",
    "        if uploaded_file is not None:\n",
    "            df = pd.read_csv(uploaded_file)\n",
    "\n",
    "            if \"review\" not in df.columns:\n",
    "                st.error(\"The uploaded CSV must have a column named 'review'.\")\n",
    "            else:\n",
    "                st.write(\"Processing reviews... This may take some time.\")\n",
    "\n",
    "                sentiments = []\n",
    "                for review in df[\"review\"]:\n",
    "                    sentiment_prompt = f\"Classify the following review as 'Positive', 'Negative', or 'Neutral': {review}\"\n",
    "                    response = ollama.generate(model=\"llama3.2\", prompt=sentiment_prompt)\n",
    "                    sentiments.append(response.get(\"response\", \"Unknown\"))\n",
    "\n",
    "                df[\"Sentiment\"] = sentiments\n",
    "\n",
    "                # Display results\n",
    "                st.dataframe(df)\n",
    "\n",
    "                # Create pie chart\n",
    "                sentiment_counts = df[\"Sentiment\"].value_counts()\n",
    "                fig = px.pie(\n",
    "                    names=sentiment_counts.index,\n",
    "                    values=sentiment_counts.values,\n",
    "                    title=\"Sentiment Distribution\",\n",
    "                    color=sentiment_counts.index,\n",
    "                    color_discrete_map={\"Positive\": \"green\", \"Negative\": \"red\", \"Neutral\": \"gray\"},\n",
    "                )\n",
    "\n",
    "                st.plotly_chart(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b1fb6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
